# ğŸ§  Offline AI Text Summarizer

A fully **offline**, privacy-focused web-based application that allows users to upload or paste long blocks of text and receive high-quality summaries using local AI models.

> âœ… Built with **Python**, **JavaScript**, and **C++**  
> âœ… No internet required after setup  
> âœ… Ideal for secure environments, schools, or offline devices

---

## ğŸ“ Project Structure

```
offline-ai-text-summarizer/
â”œâ”€â”€ app.py                # Flask backend (serves model + API)
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ parser.py         # PDF/TXT file parsing logic
â”œâ”€â”€ cpp/
â”‚   â””â”€â”€ tokenizer.cpp     # High-speed C++ chunking (via pybind11)
â”œâ”€â”€ cpp_build/            # Compiled C++ shared library
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html        # User interface
â”‚   â”œâ”€â”€ tutorial.html     # (Optional) Visual help file
â”‚   â”œâ”€â”€ styles.css        # Modern CSS styling
â”‚   â””â”€â”€ script.js         # Frontend JS to handle input/output
â”œâ”€â”€ build_cpp.sh          # Shell script to compile C++ tokenizer
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # This file
```

---

## ğŸš€ Features

- ğŸ”’ Fully offline (runs locally, no cloud API)
- ğŸ“„ Summarize plain text, PDFs, or pasted content
- ğŸ§  Fast and accurate with `distilbart-cnn-12-6` model
- ğŸ§© C++ chunking for speed and efficiency
- ğŸ’¡ Clean and responsive UI for all screen sizes
- ğŸ‘¶ Beginner-friendly interface (no coding required)

---

## ğŸ›  Setup Instructions

> ğŸ **Python 3.8+**, ğŸ§± **g++**, ğŸ“¦ **pip**, and ğŸ–¥ï¸ basic terminal access required

1. **Clone or extract the project**
   ```bash
   git clone https://github.com/yourname/offline-ai-summarizer.git
   cd offline-ai-summarizer
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Download summarization model (only once)**
   ```bash
   python -c "from transformers import pipeline; pipeline('summarization', model='sshleifer/distilbart-cnn-12-6')"
   ```

4. **Build the C++ tokenizer module**
   ```bash
   chmod +x build_cpp.sh
   ./build_cpp.sh
   ```

5. **Run the Flask server**
   ```bash
   python app.py
   ```

6. **Visit the app**
   ```
   http://localhost:5000
   ```

---

## ğŸ“‚ Supported Input Types

- âœ… Plain text (`.txt`)
- âœ… PDF files (`.pdf`)
- âœ… Manual paste input

---

## ğŸ§  Model Info

- **Model**: `sshleifer/distilbart-cnn-12-6`  
- **Framework**: HuggingFace Transformers  
- **Inference**: CPU or GPU (uses GPU if available)

---

## ğŸ›¡ï¸ Offline & Secure

- No internet connection is required after initial model download
- Great for air-gapped systems or child-safe educational environments

---

## â“ Troubleshooting

- ğŸ”¥ **Model takes time to load first time**: Wait ~10â€“20s
- ğŸ§± **C++ not compiling?** Install:
  ```bash
  sudo apt install g++ python3-dev
  pip install pybind11
  ```

---

## ğŸ“œ License

MIT License â€“ free to use, modify, and distribute.

---

## ğŸ‘¨â€ğŸ’» Author

**Aaryan Banskota**  
*Full-stack + AI Developer*

GitHub: [@Aaryanbanskota](https://github.com/Aaryanbanskota)
